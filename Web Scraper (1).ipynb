{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping through popular websites to collect images of celebrites and information about them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import *\n",
    "import requests as rq\n",
    "import os\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = rq.get(\"https://www.imdb.com/list/ls068010962/\")\n",
    "soup2 = BeautifulSoup(r2.text, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an empty link for storing the extracted image links\n",
    "links = []\n",
    "\n",
    "x = soup2.select('img[src^=\"https://m.media-amazon.com/images/M\"]')\n",
    "\n",
    "for img in x:\n",
    "    links.append(img['src'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a folder to store the downloaded  images\n",
    "os.mkdir('celebpic1')\n",
    "i = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting images from the given URL\n",
    "for index, img_link in enumerate(links):\n",
    "    if i <= 200:\n",
    "        img_data = rq.get(img_link).content\n",
    "        with open('celebpic1/'+str(index+1)+'.jpg','wb+') as f:\n",
    "        f.write(img_data)\n",
    "        i += 1\n",
    "    else:\n",
    "        f.close()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = rq.get(\"https://www.imdb.com/list/ls068010962/\")\n",
    "soup2 = BeautifulSoup(r2.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aamir Khan'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extracting names from the given URL\n",
    "names = soup2.find_all('h3')\n",
    "' '.join(names[0].text.split()[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "link2 = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the extracted names to the link2 list\n",
    "for i in names:\n",
    "    link2.append(' '.join(i.text.split()[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. \\n Aamir Khan\\n '"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "birth = []\n",
    "height = []\n",
    "net_worth = []\n",
    "spouse = []\n",
    "upcoming_movies = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "z = 0\n",
    "#loopig for every celebrity name stored in the link2 list \n",
    "for j in link2[:]:\n",
    "    q = j.replace('','+')\n",
    "    r2 = rq.get(\"https://www.google.com/search?q={}&ie=UTF-8\".format(q))\n",
    "    soup2 = BeautifulSoup(r2.text, \"html.parser\")\n",
    "    \n",
    "    #creating flag variables for the attributes\n",
    "    b=False\n",
    "    h=False\n",
    "    w=False\n",
    "    s=False\n",
    "    t=False\n",
    "    \n",
    "    #iterating through different attributes to get desired text\n",
    "    for i in range(0,len(soup2.find_all('span',class_= 'BNeawe s3v9rd AP7Wnd'))):\n",
    "    \n",
    "        if soup2.find_all('span', class_='BNeawe s3v9rd AP7Wnd')[i].text == 'Born':\n",
    "            birth.append( soup2.find_all('span', class_='BNeawe tAd8D AP7Wnd')[i].text)\n",
    "            b = True\n",
    "        \n",
    "        if soup2.find_all('span', class_='BNeawe s3v9rd AP7Wnd')[i].text == 'Height':\n",
    "            height.append( soup2.find_all('span', class_='BNeawe tAd8D AP7Wnd')[i].text)\n",
    "            h = True\n",
    "        \n",
    "        if soup2.find_all('span', class_='BNeawe s3v9rd AP7Wnd')[i].text == 'Net worth':\n",
    "            net_worth.append( soup2.find_all('span', class_='BNeawe tAd8D AP7Wnd')[i].text)\n",
    "            w = True\n",
    "        \n",
    "        if soup2.find_all('span', class_='BNeawe s3v9rd AP7Wnd')[i].text == 'Spouse':\n",
    "            spouse.append( soup2.find_all('span', class_='BNeawe tAd8D AP7Wnd')[i].text)\n",
    "            s = True\n",
    "        \n",
    "        if soup2.find_all('span', class_='BNeawe s3v9rd AP7Wnd')[i].text == 'Upcoming movies':\n",
    "            upcoming_movies.append( soup2.find_all('span', class_='BNeawe tAd8D AP7Wnd')[i].text)\n",
    "            t = True\n",
    "        \n",
    "    if b == False:\n",
    "        birth.append(np.nan)\n",
    "    if h == False:\n",
    "        height.append(np.nan)\n",
    "    if w == False:\n",
    "        net_worth.append(np.nan)\n",
    "    if s == False:\n",
    "        spouse.append(np.nan)\n",
    "    if t == False:\n",
    "        upcoming_movies.append(np.nan)\n",
    "    \n",
    "    z=z+1\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a data frame with the extracted data stored in various lists\n",
    "df = pd.DataFrame(list(zip(link2,birth,height,net_worth,upcoming_movies,spouse)),columns = ['Name','birth','height','net_worth','upcoming_movies','spouse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('celeb_details')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
